F:\Anaconda\envs\pytorch\python.exe F:/NLP大作业/SimCSE-Pytorch-master/ESimCSE/tongyi_distill_train.py
2024-12-24 15:28:13.740 | INFO     | __main__:<module>:499 - Starting training process with knowledge distillation from Tongyi embeddings.
2024-12-24 15:28:13.740 | INFO     | __main__:<module>:500 - Namespace(batch_size=16, data_path='../data/STS-B/', device='cuda:0', dropout=0.15, dup_rate=0.15, lr=3e-05, max_length=50, pooler='first-last-avg', pretrain_model_path='F:\\models\\bert-base-chinese', q_size=64, save_path='./model_save', teacher_save_path='./tongyi_embeddings.json')
Using cuda:0 device.

2024-12-24 15:28:13.986 | INFO     | __main__:<module>:505 - Test Embeddings长度: 1024
2024-12-24 15:28:14.008 | INFO     | __main__:main:424 - Generating/updating embeddings...
2024-12-24 15:28:17.014 | INFO     | __main__:generate_teacher_embeddings:166 - Total sentences: 10462, Remaining to embed: 0
Generating embeddings: 0it [00:00, ?it/s]
2024-12-24 15:28:17.016 | INFO     | __main__:generate_teacher_embeddings:193 - Embedding generation completed. Saved to ./tongyi_embeddings.json
original_dim: 1024
PCA: n_components: 768
2024-12-24 15:28:20.847 | INFO     | __main__:train_with_distillation:322 - Applying PCA to teacher embeddings...
Training:   0%|          | 0/654 [00:00<?, ?it/s]F:\Anaconda\envs\pytorch\lib\site-packages\transformers\models\bert\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\cb\pytorch_1000000000000\work\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:455.)
  attn_output = torch.nn.functional.scaled_dot_product_attention(
Training:   0%|          | 3/654 [01:00<2:50:02, 15.67s/it] 2024-12-24 15:29:22.079 | INFO     | __main__:train_with_distillation:358 - Batch 5/654 - loss: 0.0357
Training:   0%|          | 3/654 [01:15<2:50:02, 15.67s/it]2024-12-24 15:30:31.388 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.5669 at batch 5, model saved.
Training:   1%|▏         | 9/654 [02:10<1:38:50,  9.19s/it]2024-12-24 15:30:31.758 | INFO     | __main__:train_with_distillation:358 - Batch 10/654 - loss: 0.0235
Training:   1%|▏         | 9/654 [02:25<1:38:50,  9.19s/it]2024-12-24 15:31:44.810 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.5716 at batch 10, model saved.
Training:   2%|▏         | 14/654 [03:23<1:38:38,  9.25s/it]2024-12-24 15:31:45.173 | INFO     | __main__:train_with_distillation:358 - Batch 15/654 - loss: 0.0163
Training:   2%|▏         | 14/654 [03:35<1:38:38,  9.25s/it]2024-12-24 15:32:59.022 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.6051 at batch 15, model saved.
Training:   3%|▎         | 19/654 [04:37<1:38:45,  9.33s/it]2024-12-24 15:32:59.391 | INFO     | __main__:train_with_distillation:358 - Batch 20/654 - loss: 0.0170
Training:   3%|▎         | 19/654 [04:55<1:38:45,  9.33s/it]2024-12-24 15:34:07.216 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.6076 at batch 20, model saved.
Training:   4%|▎         | 24/654 [05:45<1:33:00,  8.86s/it]2024-12-24 15:34:07.576 | INFO     | __main__:train_with_distillation:358 - Batch 25/654 - loss: 0.0137
Training:   4%|▍         | 29/654 [06:47<1:24:42,  8.13s/it]2024-12-24 15:35:08.941 | INFO     | __main__:train_with_distillation:358 - Batch 30/654 - loss: 0.0125
Training:   5%|▌         | 34/654 [07:44<1:18:16,  7.57s/it]2024-12-24 15:36:06.556 | INFO     | __main__:train_with_distillation:358 - Batch 35/654 - loss: 0.0116
Training:   6%|▌         | 39/654 [08:49<1:21:15,  7.93s/it]2024-12-24 15:37:10.745 | INFO     | __main__:train_with_distillation:358 - Batch 40/654 - loss: 0.0106
Training:   7%|▋         | 44/654 [09:50<1:19:06,  7.78s/it]2024-12-24 15:38:11.698 | INFO     | __main__:train_with_distillation:358 - Batch 45/654 - loss: 0.0106
Training:   7%|▋         | 49/654 [10:50<1:17:23,  7.68s/it]2024-12-24 15:39:11.958 | INFO     | __main__:train_with_distillation:358 - Batch 50/654 - loss: 0.0101
Training:   8%|▊         | 54/654 [11:48<1:14:57,  7.50s/it]2024-12-24 15:40:10.502 | INFO     | __main__:train_with_distillation:358 - Batch 55/654 - loss: 0.0094
Training:   9%|▉         | 59/654 [12:50<1:15:53,  7.65s/it]2024-12-24 15:41:11.690 | INFO     | __main__:train_with_distillation:358 - Batch 60/654 - loss: 0.0091
Training:  10%|▉         | 64/654 [13:49<1:14:16,  7.55s/it]2024-12-24 15:42:11.034 | INFO     | __main__:train_with_distillation:358 - Batch 65/654 - loss: 0.0094
Training:  10%|▉         | 64/654 [14:06<1:14:16,  7.55s/it]2024-12-24 15:43:08.622 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.6091 at batch 65, model saved.
Training:  11%|█         | 69/654 [14:47<1:12:11,  7.40s/it]2024-12-24 15:43:08.996 | INFO     | __main__:train_with_distillation:358 - Batch 70/654 - loss: 0.0083
Training:  11%|█▏        | 74/654 [15:47<1:13:09,  7.57s/it]2024-12-24 15:44:09.550 | INFO     | __main__:train_with_distillation:358 - Batch 75/654 - loss: 0.0080
Training:  12%|█▏        | 79/654 [16:46<1:11:53,  7.50s/it]2024-12-24 15:45:08.607 | INFO     | __main__:train_with_distillation:358 - Batch 80/654 - loss: 0.0074
Training:  13%|█▎        | 84/654 [17:46<1:11:33,  7.53s/it]2024-12-24 15:46:08.340 | INFO     | __main__:train_with_distillation:358 - Batch 85/654 - loss: 0.0075
Training:  14%|█▎        | 89/654 [18:51<1:15:17,  7.99s/it]2024-12-24 15:47:13.518 | INFO     | __main__:train_with_distillation:358 - Batch 90/654 - loss: 0.0073
Training:  14%|█▍        | 94/654 [19:54<1:14:22,  7.97s/it]2024-12-24 15:48:16.480 | INFO     | __main__:train_with_distillation:358 - Batch 95/654 - loss: 0.0063
Training:  15%|█▌        | 99/654 [20:53<1:10:23,  7.61s/it]2024-12-24 15:49:15.189 | INFO     | __main__:train_with_distillation:358 - Batch 100/654 - loss: 0.0059
Training:  16%|█▌        | 104/654 [21:54<1:10:37,  7.70s/it]2024-12-24 15:50:16.540 | INFO     | __main__:train_with_distillation:358 - Batch 105/654 - loss: 0.0054
Training:  17%|█▋        | 109/654 [22:51<1:06:43,  7.35s/it]2024-12-24 15:51:13.151 | INFO     | __main__:train_with_distillation:358 - Batch 110/654 - loss: 0.0053
Training:  17%|█▋        | 109/654 [23:06<1:06:43,  7.35s/it]2024-12-24 15:52:09.386 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.6111 at batch 110, model saved.
Training:  17%|█▋        | 114/654 [23:48<1:04:59,  7.22s/it]2024-12-24 15:52:09.750 | INFO     | __main__:train_with_distillation:358 - Batch 115/654 - loss: 0.0049
Training:  17%|█▋        | 114/654 [24:06<1:04:59,  7.22s/it]2024-12-24 15:53:06.090 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.6310 at batch 115, model saved.
Training:  18%|█▊        | 119/654 [24:44<1:04:05,  7.19s/it]2024-12-24 15:53:06.453 | INFO     | __main__:train_with_distillation:358 - Batch 120/654 - loss: 0.0055
Training:  18%|█▊        | 119/654 [24:56<1:04:05,  7.19s/it]2024-12-24 15:54:09.565 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.6386 at batch 120, model saved.
Training:  19%|█▉        | 124/654 [25:48<1:08:20,  7.74s/it]2024-12-24 15:54:09.948 | INFO     | __main__:train_with_distillation:358 - Batch 125/654 - loss: 0.0047
Training:  19%|█▉        | 124/654 [26:06<1:08:20,  7.74s/it]2024-12-24 15:55:15.243 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.6456 at batch 125, model saved.
Training:  20%|█▉        | 129/654 [26:54<1:10:57,  8.11s/it]2024-12-24 15:55:15.636 | INFO     | __main__:train_with_distillation:358 - Batch 130/654 - loss: 0.0046
Training:  20%|██        | 134/654 [27:54<1:07:44,  7.82s/it]2024-12-24 15:56:16.259 | INFO     | __main__:train_with_distillation:358 - Batch 135/654 - loss: 0.0051
Training:  21%|██▏       | 139/654 [28:56<1:06:47,  7.78s/it]2024-12-24 15:57:17.663 | INFO     | __main__:train_with_distillation:358 - Batch 140/654 - loss: 0.0048
Training:  22%|██▏       | 144/654 [29:46<58:03,  6.83s/it]  2024-12-24 15:58:07.739 | INFO     | __main__:train_with_distillation:358 - Batch 145/654 - loss: 0.0049
Training:  23%|██▎       | 149/654 [30:38<56:25,  6.70s/it]  2024-12-24 15:59:00.229 | INFO     | __main__:train_with_distillation:358 - Batch 150/654 - loss: 0.0040
Training:  23%|██▎       | 149/654 [30:56<56:25,  6.70s/it]2024-12-24 15:59:59.491 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.6491 at batch 150, model saved.
Training:  24%|██▎       | 154/654 [31:38<1:00:26,  7.25s/it]2024-12-24 15:59:59.879 | INFO     | __main__:train_with_distillation:358 - Batch 155/654 - loss: 0.0038
Training:  24%|██▎       | 154/654 [31:56<1:00:26,  7.25s/it]2024-12-24 16:00:59.304 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.6518 at batch 155, model saved.
Training:  24%|██▍       | 159/654 [32:38<1:01:31,  7.46s/it]2024-12-24 16:00:59.696 | INFO     | __main__:train_with_distillation:358 - Batch 160/654 - loss: 0.0035
Training:  25%|██▌       | 164/654 [33:38<1:01:35,  7.54s/it]2024-12-24 16:01:59.683 | INFO     | __main__:train_with_distillation:358 - Batch 165/654 - loss: 0.0036
Training:  26%|██▌       | 169/654 [34:40<1:02:57,  7.79s/it]2024-12-24 16:03:02.332 | INFO     | __main__:train_with_distillation:358 - Batch 170/654 - loss: 0.0032
Training:  27%|██▋       | 174/654 [35:45<1:04:19,  8.04s/it]2024-12-24 16:04:06.988 | INFO     | __main__:train_with_distillation:358 - Batch 175/654 - loss: 0.0691
Training:  27%|██▋       | 179/654 [36:46<1:01:54,  7.82s/it]2024-12-24 16:05:07.965 | INFO     | __main__:train_with_distillation:358 - Batch 180/654 - loss: 0.0032
Training:  28%|██▊       | 184/654 [37:48<1:01:09,  7.81s/it]2024-12-24 16:06:09.686 | INFO     | __main__:train_with_distillation:358 - Batch 185/654 - loss: 0.0055
Training:  29%|██▉       | 189/654 [38:45<57:56,  7.48s/it]  2024-12-24 16:07:07.453 | INFO     | __main__:train_with_distillation:358 - Batch 190/654 - loss: 0.0036
Training:  30%|██▉       | 194/654 [39:43<56:11,  7.33s/it]  2024-12-24 16:08:04.844 | INFO     | __main__:train_with_distillation:358 - Batch 195/654 - loss: 0.0043
Training:  30%|███       | 199/654 [40:40<55:12,  7.28s/it]  2024-12-24 16:09:02.218 | INFO     | __main__:train_with_distillation:358 - Batch 200/654 - loss: 0.0053
Training:  31%|███       | 204/654 [41:34<52:20,  6.98s/it]  2024-12-24 16:09:56.169 | INFO     | __main__:train_with_distillation:358 - Batch 205/654 - loss: 0.0038
Training:  32%|███▏      | 209/654 [42:22<47:20,  6.38s/it]  2024-12-24 16:10:44.174 | INFO     | __main__:train_with_distillation:358 - Batch 210/654 - loss: 0.0039
Training:  33%|███▎      | 214/654 [43:09<44:44,  6.10s/it]  2024-12-24 16:11:31.206 | INFO     | __main__:train_with_distillation:358 - Batch 215/654 - loss: 0.0034
Training:  33%|███▎      | 219/654 [43:56<43:40,  6.02s/it]  2024-12-24 16:12:18.523 | INFO     | __main__:train_with_distillation:358 - Batch 220/654 - loss: 0.0031
Training:  34%|███▍      | 224/654 [44:45<44:03,  6.15s/it]  2024-12-24 16:13:07.642 | INFO     | __main__:train_with_distillation:358 - Batch 225/654 - loss: 0.0034
Training:  35%|███▌      | 229/654 [45:35<43:53,  6.20s/it]  2024-12-24 16:13:56.823 | INFO     | __main__:train_with_distillation:358 - Batch 230/654 - loss: 0.0031
Training:  36%|███▌      | 234/654 [46:24<43:43,  6.25s/it]  2024-12-24 16:14:46.415 | INFO     | __main__:train_with_distillation:358 - Batch 235/654 - loss: 0.0028
Training:  37%|███▋      | 239/654 [47:14<43:19,  6.26s/it]  2024-12-24 16:15:35.983 | INFO     | __main__:train_with_distillation:358 - Batch 240/654 - loss: 0.0048
Training:  37%|███▋      | 244/654 [48:03<42:50,  6.27s/it]  2024-12-24 16:16:25.551 | INFO     | __main__:train_with_distillation:358 - Batch 245/654 - loss: 0.0024
Training:  38%|███▊      | 249/654 [48:53<42:14,  6.26s/it]  2024-12-24 16:17:14.962 | INFO     | __main__:train_with_distillation:358 - Batch 250/654 - loss: 0.0023
Training:  39%|███▉      | 254/654 [49:42<41:40,  6.25s/it]  2024-12-24 16:18:04.357 | INFO     | __main__:train_with_distillation:358 - Batch 255/654 - loss: 0.0020
Training:  40%|███▉      | 259/654 [50:32<41:08,  6.25s/it]  2024-12-24 16:18:53.732 | INFO     | __main__:train_with_distillation:358 - Batch 260/654 - loss: 0.0021
Training:  40%|████      | 264/654 [51:21<40:37,  6.25s/it]  2024-12-24 16:19:43.105 | INFO     | __main__:train_with_distillation:358 - Batch 265/654 - loss: 0.0019
Training:  41%|████      | 269/654 [52:10<40:05,  6.25s/it]  2024-12-24 16:20:32.482 | INFO     | __main__:train_with_distillation:358 - Batch 270/654 - loss: 0.0022
Training:  42%|████▏     | 274/654 [53:00<39:34,  6.25s/it]2024-12-24 16:21:21.883 | INFO     | __main__:train_with_distillation:358 - Batch 275/654 - loss: 0.0017
Training:  43%|████▎     | 279/654 [53:49<39:09,  6.26s/it]2024-12-24 16:22:11.454 | INFO     | __main__:train_with_distillation:358 - Batch 280/654 - loss: 0.0020
Training:  43%|████▎     | 284/654 [54:39<38:40,  6.27s/it]2024-12-24 16:23:01.026 | INFO     | __main__:train_with_distillation:358 - Batch 285/654 - loss: 0.0018
Training:  44%|████▍     | 289/654 [55:28<38:03,  6.26s/it]2024-12-24 16:23:50.421 | INFO     | __main__:train_with_distillation:358 - Batch 290/654 - loss: 0.0016
Training:  45%|████▍     | 294/654 [56:18<37:35,  6.27s/it]2024-12-24 16:24:39.990 | INFO     | __main__:train_with_distillation:358 - Batch 295/654 - loss: 0.0017
Training:  46%|████▌     | 299/654 [57:08<37:12,  6.29s/it]2024-12-24 16:25:29.784 | INFO     | __main__:train_with_distillation:358 - Batch 300/654 - loss: 0.0015
Training:  46%|████▋     | 304/654 [57:57<36:34,  6.27s/it]2024-12-24 16:26:19.260 | INFO     | __main__:train_with_distillation:358 - Batch 305/654 - loss: 0.0015
Training:  47%|████▋     | 309/654 [58:45<35:04,  6.10s/it]2024-12-24 16:27:06.775 | INFO     | __main__:train_with_distillation:358 - Batch 310/654 - loss: 0.0015
Training:  48%|████▊     | 314/654 [59:32<33:58,  6.00s/it]2024-12-24 16:27:53.752 | INFO     | __main__:train_with_distillation:358 - Batch 315/654 - loss: 0.0013
Training:  49%|████▉     | 319/654 [1:00:19<33:23,  5.98s/it]2024-12-24 16:28:40.944 | INFO     | __main__:train_with_distillation:358 - Batch 320/654 - loss: 0.0146
Training:  50%|████▉     | 324/654 [1:01:06<32:45,  5.96s/it]2024-12-24 16:29:27.945 | INFO     | __main__:train_with_distillation:358 - Batch 325/654 - loss: 0.0022
Training:  50%|█████     | 329/654 [1:01:53<32:07,  5.93s/it]2024-12-24 16:30:14.722 | INFO     | __main__:train_with_distillation:358 - Batch 330/654 - loss: 0.0021
Training:  51%|█████     | 334/654 [1:02:39<31:35,  5.92s/it]2024-12-24 16:31:01.494 | INFO     | __main__:train_with_distillation:358 - Batch 335/654 - loss: 0.0027
Training:  52%|█████▏    | 339/654 [1:03:26<31:09,  5.94s/it]2024-12-24 16:31:48.464 | INFO     | __main__:train_with_distillation:358 - Batch 340/654 - loss: 0.0035
Training:  53%|█████▎    | 344/654 [1:04:13<30:37,  5.93s/it]2024-12-24 16:32:35.271 | INFO     | __main__:train_with_distillation:358 - Batch 345/654 - loss: 0.0025
Training:  53%|█████▎    | 349/654 [1:05:00<30:15,  5.95s/it]2024-12-24 16:33:22.434 | INFO     | __main__:train_with_distillation:358 - Batch 350/654 - loss: 0.0037
Training:  54%|█████▍    | 354/654 [1:05:47<29:39,  5.93s/it]2024-12-24 16:34:09.228 | INFO     | __main__:train_with_distillation:358 - Batch 355/654 - loss: 0.0024
Training:  55%|█████▍    | 359/654 [1:06:34<29:07,  5.92s/it]2024-12-24 16:34:56.019 | INFO     | __main__:train_with_distillation:358 - Batch 360/654 - loss: 0.0018
Training:  56%|█████▌    | 364/654 [1:07:21<28:37,  5.92s/it]2024-12-24 16:35:42.819 | INFO     | __main__:train_with_distillation:358 - Batch 365/654 - loss: 0.0018
Training:  56%|█████▋    | 369/654 [1:08:07<28:06,  5.92s/it]2024-12-24 16:36:29.583 | INFO     | __main__:train_with_distillation:358 - Batch 370/654 - loss: 0.0022
Training:  57%|█████▋    | 374/654 [1:08:55<27:47,  5.95s/it]2024-12-24 16:37:16.771 | INFO     | __main__:train_with_distillation:358 - Batch 375/654 - loss: 0.0019
Training:  58%|█████▊    | 379/654 [1:09:42<27:29,  6.00s/it]2024-12-24 16:38:04.370 | INFO     | __main__:train_with_distillation:358 - Batch 380/654 - loss: 0.0021
Training:  59%|█████▊    | 384/654 [1:10:29<26:53,  5.98s/it]2024-12-24 16:38:51.549 | INFO     | __main__:train_with_distillation:358 - Batch 385/654 - loss: 0.0019
Training:  59%|█████▉    | 389/654 [1:11:18<26:59,  6.11s/it]2024-12-24 16:39:40.395 | INFO     | __main__:train_with_distillation:358 - Batch 390/654 - loss: 0.0015
Training:  60%|██████    | 394/654 [1:12:07<26:38,  6.15s/it]2024-12-24 16:40:29.147 | INFO     | __main__:train_with_distillation:358 - Batch 395/654 - loss: 0.0016
Training:  61%|██████    | 399/654 [1:12:55<26:01,  6.12s/it]2024-12-24 16:41:17.467 | INFO     | __main__:train_with_distillation:358 - Batch 400/654 - loss: 0.0014
Training:  62%|██████▏   | 404/654 [1:13:44<25:33,  6.13s/it]2024-12-24 16:42:05.979 | INFO     | __main__:train_with_distillation:358 - Batch 405/654 - loss: 0.0012
Training:  63%|██████▎   | 409/654 [1:14:32<24:47,  6.07s/it]2024-12-24 16:42:53.716 | INFO     | __main__:train_with_distillation:358 - Batch 410/654 - loss: 0.0013
Training:  63%|██████▎   | 414/654 [1:15:19<24:10,  6.04s/it]2024-12-24 16:43:41.357 | INFO     | __main__:train_with_distillation:358 - Batch 415/654 - loss: 0.0017
Training:  64%|██████▍   | 419/654 [1:16:07<23:34,  6.02s/it]2024-12-24 16:44:28.847 | INFO     | __main__:train_with_distillation:358 - Batch 420/654 - loss: 0.0015
Training:  65%|██████▍   | 424/654 [1:16:54<23:00,  6.00s/it]2024-12-24 16:45:16.221 | INFO     | __main__:train_with_distillation:358 - Batch 425/654 - loss: 0.0011
Training:  66%|██████▌   | 429/654 [1:17:41<22:25,  5.98s/it]2024-12-24 16:46:03.385 | INFO     | __main__:train_with_distillation:358 - Batch 430/654 - loss: 0.0012
Training:  66%|██████▋   | 434/654 [1:18:28<21:50,  5.96s/it]2024-12-24 16:46:50.374 | INFO     | __main__:train_with_distillation:358 - Batch 435/654 - loss: 0.0013
Training:  67%|██████▋   | 439/654 [1:19:15<21:18,  5.95s/it]2024-12-24 16:47:37.340 | INFO     | __main__:train_with_distillation:358 - Batch 440/654 - loss: 0.0059
Training:  68%|██████▊   | 444/654 [1:20:02<20:37,  5.89s/it]2024-12-24 16:48:23.735 | INFO     | __main__:train_with_distillation:358 - Batch 445/654 - loss: 0.0013
Training:  69%|██████▊   | 449/654 [1:20:48<20:04,  5.88s/it]2024-12-24 16:49:10.121 | INFO     | __main__:train_with_distillation:358 - Batch 450/654 - loss: 0.0015
Training:  69%|██████▉   | 454/654 [1:21:35<19:37,  5.89s/it]2024-12-24 16:49:56.692 | INFO     | __main__:train_with_distillation:358 - Batch 455/654 - loss: 0.0015
Training:  70%|███████   | 459/654 [1:22:21<19:09,  5.89s/it]2024-12-24 16:50:43.277 | INFO     | __main__:train_with_distillation:358 - Batch 460/654 - loss: 0.0013
Training:  71%|███████   | 464/654 [1:23:08<18:39,  5.89s/it]2024-12-24 16:51:29.865 | INFO     | __main__:train_with_distillation:358 - Batch 465/654 - loss: 0.0011
Training:  72%|███████▏  | 469/654 [1:23:55<18:26,  5.98s/it]2024-12-24 16:52:17.475 | INFO     | __main__:train_with_distillation:358 - Batch 470/654 - loss: 0.0010
Training:  72%|███████▏  | 474/654 [1:24:43<18:01,  6.01s/it]2024-12-24 16:53:05.077 | INFO     | __main__:train_with_distillation:358 - Batch 475/654 - loss: 0.0013
Training:  73%|███████▎  | 479/654 [1:25:30<17:29,  6.00s/it]2024-12-24 16:53:52.452 | INFO     | __main__:train_with_distillation:358 - Batch 480/654 - loss: 0.0010
Training:  74%|███████▍  | 484/654 [1:26:18<17:04,  6.03s/it]2024-12-24 16:54:40.239 | INFO     | __main__:train_with_distillation:358 - Batch 485/654 - loss: 0.0012
Training:  75%|███████▍  | 489/654 [1:27:05<16:31,  6.01s/it]2024-12-24 16:55:27.606 | INFO     | __main__:train_with_distillation:358 - Batch 490/654 - loss: 0.0009
Training:  76%|███████▌  | 494/654 [1:27:53<15:59,  6.00s/it]2024-12-24 16:56:14.973 | INFO     | __main__:train_with_distillation:358 - Batch 495/654 - loss: 0.0009
Training:  76%|███████▋  | 499/654 [1:28:40<15:32,  6.02s/it]2024-12-24 16:57:02.609 | INFO     | __main__:train_with_distillation:358 - Batch 500/654 - loss: 0.0010
Training:  77%|███████▋  | 504/654 [1:29:28<15:02,  6.02s/it]2024-12-24 16:57:50.149 | INFO     | __main__:train_with_distillation:358 - Batch 505/654 - loss: 0.0009
Training:  78%|███████▊  | 509/654 [1:30:15<14:30,  6.00s/it]2024-12-24 16:58:37.567 | INFO     | __main__:train_with_distillation:358 - Batch 510/654 - loss: 0.0009
Training:  79%|███████▊  | 514/654 [1:31:03<13:59,  6.00s/it]2024-12-24 16:59:24.924 | INFO     | __main__:train_with_distillation:358 - Batch 515/654 - loss: 0.0011
Training:  79%|███████▉  | 519/654 [1:32:09<17:00,  7.56s/it]2024-12-24 17:00:31.217 | INFO     | __main__:train_with_distillation:358 - Batch 520/654 - loss: 0.0011
Training:  80%|████████  | 524/654 [1:33:13<17:07,  7.90s/it]2024-12-24 17:01:35.180 | INFO     | __main__:train_with_distillation:358 - Batch 525/654 - loss: 0.0011
Training:  81%|████████  | 529/654 [1:34:01<14:00,  6.73s/it]2024-12-24 17:02:23.488 | INFO     | __main__:train_with_distillation:358 - Batch 530/654 - loss: 0.0009
Training:  82%|████████▏ | 534/654 [1:34:54<13:21,  6.68s/it]2024-12-24 17:03:16.123 | INFO     | __main__:train_with_distillation:358 - Batch 535/654 - loss: 0.0011
Training:  82%|████████▏ | 539/654 [1:35:55<14:02,  7.33s/it]2024-12-24 17:04:16.766 | INFO     | __main__:train_with_distillation:358 - Batch 540/654 - loss: 0.0227
Training:  83%|████████▎ | 544/654 [1:36:53<13:32,  7.39s/it]2024-12-24 17:05:15.509 | INFO     | __main__:train_with_distillation:358 - Batch 545/654 - loss: 0.0017
Training:  84%|████████▍ | 549/654 [1:37:49<12:32,  7.17s/it]2024-12-24 17:06:11.278 | INFO     | __main__:train_with_distillation:358 - Batch 550/654 - loss: 0.0013
Training:  85%|████████▍ | 554/654 [1:38:42<11:24,  6.84s/it]2024-12-24 17:07:04.003 | INFO     | __main__:train_with_distillation:358 - Batch 555/654 - loss: 0.0013
Training:  85%|████████▌ | 559/654 [1:39:33<10:29,  6.63s/it]2024-12-24 17:07:55.493 | INFO     | __main__:train_with_distillation:358 - Batch 560/654 - loss: 0.0972
Training:  86%|████████▌ | 564/654 [1:40:29<10:16,  6.85s/it]2024-12-24 17:08:50.637 | INFO     | __main__:train_with_distillation:358 - Batch 565/654 - loss: 0.0015
Training:  87%|████████▋ | 569/654 [1:41:29<10:23,  7.34s/it]2024-12-24 17:09:50.707 | INFO     | __main__:train_with_distillation:358 - Batch 570/654 - loss: 0.0012
Training:  88%|████████▊ | 574/654 [1:42:37<10:55,  8.20s/it]2024-12-24 17:10:59.104 | INFO     | __main__:train_with_distillation:358 - Batch 575/654 - loss: 0.0016
Training:  89%|████████▊ | 579/654 [1:43:44<10:28,  8.38s/it]2024-12-24 17:12:06.178 | INFO     | __main__:train_with_distillation:358 - Batch 580/654 - loss: 0.0027
Training:  89%|████████▉ | 584/654 [1:44:52<09:58,  8.55s/it]2024-12-24 17:13:14.598 | INFO     | __main__:train_with_distillation:358 - Batch 585/654 - loss: 0.0011
Training:  90%|█████████ | 589/654 [1:45:58<09:04,  8.38s/it]2024-12-24 17:14:20.172 | INFO     | __main__:train_with_distillation:358 - Batch 590/654 - loss: 0.0012
Training:  91%|█████████ | 594/654 [1:47:00<08:02,  8.04s/it]2024-12-24 17:15:22.355 | INFO     | __main__:train_with_distillation:358 - Batch 595/654 - loss: 0.0010
Training:  92%|█████████▏| 599/654 [1:48:01<07:08,  7.79s/it]2024-12-24 17:16:22.952 | INFO     | __main__:train_with_distillation:358 - Batch 600/654 - loss: 0.0009
Training:  92%|█████████▏| 604/654 [1:49:06<06:42,  8.04s/it]2024-12-24 17:17:27.642 | INFO     | __main__:train_with_distillation:358 - Batch 605/654 - loss: 0.0011
Training:  93%|█████████▎| 609/654 [1:50:08<05:57,  7.94s/it]2024-12-24 17:18:30.043 | INFO     | __main__:train_with_distillation:358 - Batch 610/654 - loss: 0.0009
Training:  94%|█████████▍| 614/654 [1:51:13<05:23,  8.09s/it]2024-12-24 17:19:34.638 | INFO     | __main__:train_with_distillation:358 - Batch 615/654 - loss: 0.0009
Training:  95%|█████████▍| 619/654 [1:52:18<04:48,  8.23s/it]2024-12-24 17:20:40.393 | INFO     | __main__:train_with_distillation:358 - Batch 620/654 - loss: 0.0012
Training:  95%|█████████▌| 624/654 [1:53:22<04:03,  8.12s/it]2024-12-24 17:21:44.176 | INFO     | __main__:train_with_distillation:358 - Batch 625/654 - loss: 0.0010
Training:  96%|█████████▌| 629/654 [1:54:24<03:18,  7.95s/it]2024-12-24 17:22:46.351 | INFO     | __main__:train_with_distillation:358 - Batch 630/654 - loss: 0.0019
Training:  97%|█████████▋| 634/654 [1:55:27<02:38,  7.92s/it]2024-12-24 17:23:48.918 | INFO     | __main__:train_with_distillation:358 - Batch 635/654 - loss: 0.0010
Training:  98%|█████████▊| 639/654 [1:56:26<01:54,  7.62s/it]2024-12-24 17:24:47.915 | INFO     | __main__:train_with_distillation:358 - Batch 640/654 - loss: 0.0011
Training:  98%|█████████▊| 644/654 [1:57:26<01:15,  7.57s/it]2024-12-24 17:25:47.636 | INFO     | __main__:train_with_distillation:358 - Batch 645/654 - loss: 0.0007
Training:  99%|█████████▉| 649/654 [1:58:13<00:32,  6.53s/it]2024-12-24 17:26:34.979 | INFO     | __main__:train_with_distillation:358 - Batch 650/654 - loss: 0.0010
Training: 100%|█████████▉| 652/654 [1:59:08<00:20, 10.28s/it]2024-12-24 17:27:30.159 | INFO     | __main__:train_with_distillation:358 - Batch 654/654 - loss: 0.0009
Training: 100%|██████████| 654/654 [2:00:10<00:00, 11.02s/it]

Process finished with exit code 0
