F:\Anaconda\envs\pytorch\python.exe F:/NLP大作业/SimCSE-Pytorch-master/ESimCSE/tongyi_distill_train.py
2024-12-24 08:37:45.718 | INFO     | __main__:<module>:499 - Starting training process with knowledge distillation from Tongyi embeddings.
2024-12-24 08:37:45.719 | INFO     | __main__:<module>:500 - Namespace(batch_size=16, data_path='../data/STS-B/', device='cuda:0', dropout=0.15, dup_rate=0.15, lr=3e-05, max_length=50, pooler='first-last-avg', pretrain_model_path='F:\\models\\bert-base-chinese', q_size=64, save_path='./model_save', teacher_save_path='./cnsd_sts_train_unsup_embeddings_768.json')
Using cuda:0 device.

2024-12-24 08:37:45.988 | INFO     | __main__:<module>:505 - Test Embeddings长度: 1024
2024-12-24 08:37:46.015 | INFO     | __main__:main:424 - Generating/updating embeddings...
2024-12-24 08:37:48.383 | INFO     | __main__:generate_teacher_embeddings:166 - Total sentences: 10462, Remaining to embed: 0
Generating embeddings: 0it [00:00, ?it/s]
2024-12-24 08:37:48.389 | INFO     | __main__:generate_teacher_embeddings:193 - Embedding generation completed. Saved to ./cnsd_sts_train_unsup_embeddings_768.json
original_dim: 768
PCA: n_components: 768
2024-12-24 08:37:51.848 | INFO     | __main__:train_with_distillation:322 - Applying PCA to teacher embeddings...
2024-12-24 08:37:51.849 | INFO     | __main__:apply_pca:43 - PCA skipped because n_components (768) matches the input dimension (768).
Training:   0%|          | 0/654 [00:00<?, ?it/s]F:\Anaconda\envs\pytorch\lib\site-packages\transformers\models\bert\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\cb\pytorch_1000000000000\work\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:455.)
  attn_output = torch.nn.functional.scaled_dot_product_attention(
Training:   0%|          | 3/654 [00:52<2:26:41, 13.52s/it]2024-12-24 08:38:44.112 | INFO     | __main__:train_with_distillation:358 - Batch 5/654 - loss: 0.1276
Training:   0%|          | 3/654 [01:06<2:26:41, 13.52s/it]2024-12-24 08:39:54.849 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.5913 at batch 5, model saved.
Training:   1%|▏         | 9/654 [02:03<1:36:14,  8.95s/it]2024-12-24 08:39:55.219 | INFO     | __main__:train_with_distillation:358 - Batch 10/654 - loss: 0.0516
Training:   2%|▏         | 14/654 [03:09<1:31:37,  8.59s/it]2024-12-24 08:41:01.850 | INFO     | __main__:train_with_distillation:358 - Batch 15/654 - loss: 0.0450
Training:   3%|▎         | 19/654 [04:14<1:28:13,  8.34s/it]2024-12-24 08:42:06.833 | INFO     | __main__:train_with_distillation:358 - Batch 20/654 - loss: 0.0394
Training:   4%|▎         | 24/654 [05:19<1:26:29,  8.24s/it]2024-12-24 08:43:11.622 | INFO     | __main__:train_with_distillation:358 - Batch 25/654 - loss: 0.0384
Training:   4%|▎         | 24/654 [05:36<1:26:29,  8.24s/it]2024-12-24 08:44:15.190 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.6110 at batch 25, model saved.
Training:   4%|▍         | 29/654 [06:23<1:24:43,  8.13s/it]2024-12-24 08:44:15.551 | INFO     | __main__:train_with_distillation:358 - Batch 30/654 - loss: 0.0327
Training:   4%|▍         | 29/654 [06:36<1:24:43,  8.13s/it]2024-12-24 08:45:14.449 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.6228 at batch 30, model saved.
Training:   5%|▌         | 34/654 [07:22<1:19:41,  7.71s/it]2024-12-24 08:45:14.808 | INFO     | __main__:train_with_distillation:358 - Batch 35/654 - loss: 0.0326
Training:   5%|▌         | 34/654 [07:36<1:19:41,  7.71s/it]2024-12-24 08:46:06.557 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.6234 at batch 35, model saved.
Training:   6%|▌         | 39/654 [08:14<1:11:28,  6.97s/it]2024-12-24 08:46:06.920 | INFO     | __main__:train_with_distillation:358 - Batch 40/654 - loss: 0.0292
Training:   6%|▌         | 39/654 [08:26<1:11:28,  6.97s/it]2024-12-24 08:47:06.909 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.6272 at batch 40, model saved.
Training:   7%|▋         | 44/654 [09:15<1:15:15,  7.40s/it]2024-12-24 08:47:07.271 | INFO     | __main__:train_with_distillation:358 - Batch 45/654 - loss: 0.0256
Training:   7%|▋         | 44/654 [09:29<1:15:15,  7.40s/it]2024-12-24 08:48:08.083 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.6295 at batch 45, model saved.
Training:   7%|▋         | 49/654 [10:16<1:16:49,  7.62s/it]2024-12-24 08:48:08.445 | INFO     | __main__:train_with_distillation:358 - Batch 50/654 - loss: 0.0247
Training:   8%|▊         | 54/654 [11:17<1:16:40,  7.67s/it]2024-12-24 08:49:09.313 | INFO     | __main__:train_with_distillation:358 - Batch 55/654 - loss: 0.0202
Training:   9%|▉         | 59/654 [12:14<1:13:11,  7.38s/it]2024-12-24 08:50:06.510 | INFO     | __main__:train_with_distillation:358 - Batch 60/654 - loss: 0.0205
Training:  10%|▉         | 64/654 [13:15<1:14:19,  7.56s/it]2024-12-24 08:51:07.069 | INFO     | __main__:train_with_distillation:358 - Batch 65/654 - loss: 0.0176
Training:  11%|█         | 69/654 [14:15<1:14:10,  7.61s/it]2024-12-24 08:52:07.472 | INFO     | __main__:train_with_distillation:358 - Batch 70/654 - loss: 0.0170
Training:  11%|█▏        | 74/654 [15:14<1:12:15,  7.48s/it]2024-12-24 08:53:06.060 | INFO     | __main__:train_with_distillation:358 - Batch 75/654 - loss: 0.0143
Training:  12%|█▏        | 79/654 [16:14<1:12:26,  7.56s/it]2024-12-24 08:54:06.218 | INFO     | __main__:train_with_distillation:358 - Batch 80/654 - loss: 0.0140
Training:  13%|█▎        | 84/654 [17:15<1:13:12,  7.71s/it]2024-12-24 08:55:07.784 | INFO     | __main__:train_with_distillation:358 - Batch 85/654 - loss: 0.0125
Training:  14%|█▎        | 89/654 [18:14<1:10:41,  7.51s/it]2024-12-24 08:56:06.376 | INFO     | __main__:train_with_distillation:358 - Batch 90/654 - loss: 0.0106
Training:  14%|█▍        | 94/654 [19:15<1:11:00,  7.61s/it]2024-12-24 08:57:06.978 | INFO     | __main__:train_with_distillation:358 - Batch 95/654 - loss: 0.0107
Training:  15%|█▌        | 99/654 [20:14<1:10:11,  7.59s/it]2024-12-24 08:58:06.933 | INFO     | __main__:train_with_distillation:358 - Batch 100/654 - loss: 0.0091
Training:  16%|█▌        | 104/654 [21:16<1:10:35,  7.70s/it]2024-12-24 08:59:08.323 | INFO     | __main__:train_with_distillation:358 - Batch 105/654 - loss: 0.0081
Training:  17%|█▋        | 109/654 [22:13<1:07:08,  7.39s/it]2024-12-24 09:00:05.516 | INFO     | __main__:train_with_distillation:358 - Batch 110/654 - loss: 0.0082
Training:  17%|█▋        | 114/654 [23:00<57:34,  6.40s/it]  2024-12-24 09:00:51.970 | INFO     | __main__:train_with_distillation:358 - Batch 115/654 - loss: 0.0065
Training:  18%|█▊        | 119/654 [23:54<59:38,  6.69s/it]  2024-12-24 09:01:46.050 | INFO     | __main__:train_with_distillation:358 - Batch 120/654 - loss: 0.0060
Training:  19%|█▉        | 124/654 [24:42<55:54,  6.33s/it]  2024-12-24 09:02:34.607 | INFO     | __main__:train_with_distillation:358 - Batch 125/654 - loss: 0.0054
Training:  20%|█▉        | 129/654 [25:31<54:36,  6.24s/it]  2024-12-24 09:03:23.586 | INFO     | __main__:train_with_distillation:358 - Batch 130/654 - loss: 0.0052
Training:  20%|██        | 134/654 [26:27<58:44,  6.78s/it]  2024-12-24 09:04:19.429 | INFO     | __main__:train_with_distillation:358 - Batch 135/654 - loss: 0.0050
Training:  21%|██▏       | 139/654 [27:28<1:03:40,  7.42s/it]2024-12-24 09:05:20.774 | INFO     | __main__:train_with_distillation:358 - Batch 140/654 - loss: 0.0054
Training:  22%|██▏       | 144/654 [28:28<1:03:41,  7.49s/it]2024-12-24 09:06:20.353 | INFO     | __main__:train_with_distillation:358 - Batch 145/654 - loss: 0.0052
Training:  23%|██▎       | 149/654 [29:28<1:03:25,  7.54s/it]2024-12-24 09:07:20.138 | INFO     | __main__:train_with_distillation:358 - Batch 150/654 - loss: 0.0072
Training:  24%|██▎       | 154/654 [30:28<1:02:55,  7.55s/it]2024-12-24 09:08:19.952 | INFO     | __main__:train_with_distillation:358 - Batch 155/654 - loss: 0.0047
Training:  24%|██▍       | 159/654 [31:21<57:54,  7.02s/it]  2024-12-24 09:09:13.265 | INFO     | __main__:train_with_distillation:358 - Batch 160/654 - loss: 0.0075
Training:  25%|██▌       | 164/654 [32:20<59:57,  7.34s/it]  2024-12-24 09:10:12.685 | INFO     | __main__:train_with_distillation:358 - Batch 165/654 - loss: 0.0040
Training:  26%|██▌       | 169/654 [33:20<1:00:12,  7.45s/it]2024-12-24 09:11:12.057 | INFO     | __main__:train_with_distillation:358 - Batch 170/654 - loss: 0.0041
Training:  27%|██▋       | 174/654 [34:22<1:01:52,  7.73s/it]2024-12-24 09:12:14.441 | INFO     | __main__:train_with_distillation:358 - Batch 175/654 - loss: 0.0039
Training:  27%|██▋       | 179/654 [35:22<1:00:26,  7.64s/it]2024-12-24 09:13:14.447 | INFO     | __main__:train_with_distillation:358 - Batch 180/654 - loss: 0.0047
Training:  28%|██▊       | 184/654 [36:26<1:01:59,  7.91s/it]2024-12-24 09:14:18.200 | INFO     | __main__:train_with_distillation:358 - Batch 185/654 - loss: 0.0035
Training:  29%|██▉       | 189/654 [37:26<59:53,  7.73s/it]  2024-12-24 09:15:18.580 | INFO     | __main__:train_with_distillation:358 - Batch 190/654 - loss: 0.0036
Training:  30%|██▉       | 194/654 [38:25<57:44,  7.53s/it]  2024-12-24 09:16:17.358 | INFO     | __main__:train_with_distillation:358 - Batch 195/654 - loss: 0.0031
Training:  30%|███       | 199/654 [39:24<57:06,  7.53s/it]  2024-12-24 09:17:16.939 | INFO     | __main__:train_with_distillation:358 - Batch 200/654 - loss: 0.0028
Training:  31%|███       | 204/654 [40:25<57:18,  7.64s/it]  2024-12-24 09:18:17.852 | INFO     | __main__:train_with_distillation:358 - Batch 205/654 - loss: 0.0028
Training:  32%|███▏      | 209/654 [41:29<58:38,  7.91s/it]  2024-12-24 09:19:21.523 | INFO     | __main__:train_with_distillation:358 - Batch 210/654 - loss: 0.0027
Training:  33%|███▎      | 214/654 [42:30<57:06,  7.79s/it]  2024-12-24 09:20:22.667 | INFO     | __main__:train_with_distillation:358 - Batch 215/654 - loss: 0.0035
Training:  33%|███▎      | 219/654 [43:37<59:28,  8.20s/it]  2024-12-24 09:21:29.310 | INFO     | __main__:train_with_distillation:358 - Batch 220/654 - loss: 0.0031
Training:  34%|███▍      | 224/654 [44:44<1:00:21,  8.42s/it]2024-12-24 09:22:36.889 | INFO     | __main__:train_with_distillation:358 - Batch 225/654 - loss: 0.0039
Training:  35%|███▌      | 229/654 [45:51<59:24,  8.39s/it]  2024-12-24 09:23:43.120 | INFO     | __main__:train_with_distillation:358 - Batch 230/654 - loss: 0.0032
Training:  36%|███▌      | 234/654 [46:55<57:31,  8.22s/it]  2024-12-24 09:24:47.423 | INFO     | __main__:train_with_distillation:358 - Batch 235/654 - loss: 0.0033
Training:  37%|███▋      | 239/654 [47:59<56:08,  8.12s/it]  2024-12-24 09:25:51.227 | INFO     | __main__:train_with_distillation:358 - Batch 240/654 - loss: 0.0034
Training:  37%|███▋      | 244/654 [49:01<54:13,  7.94s/it]  2024-12-24 09:26:53.242 | INFO     | __main__:train_with_distillation:358 - Batch 245/654 - loss: 0.0033
Training:  38%|███▊      | 249/654 [50:06<54:45,  8.11s/it]  2024-12-24 09:27:58.180 | INFO     | __main__:train_with_distillation:358 - Batch 250/654 - loss: 0.0027
Training:  39%|███▉      | 254/654 [51:09<53:43,  8.06s/it]  2024-12-24 09:29:01.728 | INFO     | __main__:train_with_distillation:358 - Batch 255/654 - loss: 0.0027
Training:  40%|███▉      | 259/654 [52:09<51:06,  7.76s/it]  2024-12-24 09:30:01.912 | INFO     | __main__:train_with_distillation:358 - Batch 260/654 - loss: 0.0025
Training:  40%|████      | 264/654 [53:13<51:30,  7.92s/it]  2024-12-24 09:31:05.298 | INFO     | __main__:train_with_distillation:358 - Batch 265/654 - loss: 0.0046
Training:  41%|████      | 269/654 [54:18<52:16,  8.15s/it]  2024-12-24 09:32:10.676 | INFO     | __main__:train_with_distillation:358 - Batch 270/654 - loss: 0.0034
Training:  42%|████▏     | 274/654 [55:21<50:48,  8.02s/it]  2024-12-24 09:33:13.653 | INFO     | __main__:train_with_distillation:358 - Batch 275/654 - loss: 0.0039
Training:  43%|████▎     | 279/654 [56:25<50:11,  8.03s/it]  2024-12-24 09:34:17.246 | INFO     | __main__:train_with_distillation:358 - Batch 280/654 - loss: 0.0044
Training:  43%|████▎     | 284/654 [57:26<48:12,  7.82s/it]  2024-12-24 09:35:18.189 | INFO     | __main__:train_with_distillation:358 - Batch 285/654 - loss: 0.0037
Training:  44%|████▍     | 289/654 [58:29<48:19,  7.94s/it]  2024-12-24 09:36:21.585 | INFO     | __main__:train_with_distillation:358 - Batch 290/654 - loss: 0.0034
Training:  45%|████▍     | 294/654 [59:32<47:37,  7.94s/it]  2024-12-24 09:37:24.365 | INFO     | __main__:train_with_distillation:358 - Batch 295/654 - loss: 0.0033
Training:  46%|████▌     | 299/654 [1:00:34<46:27,  7.85s/it]  2024-12-24 09:38:26.146 | INFO     | __main__:train_with_distillation:358 - Batch 300/654 - loss: 0.0050
Training:  46%|████▋     | 304/654 [1:01:37<46:36,  7.99s/it]  2024-12-24 09:39:29.923 | INFO     | __main__:train_with_distillation:358 - Batch 305/654 - loss: 0.0027
Training:  47%|████▋     | 309/654 [1:02:45<47:54,  8.33s/it]  2024-12-24 09:40:37.284 | INFO     | __main__:train_with_distillation:358 - Batch 310/654 - loss: 0.0025
Training:  48%|████▊     | 314/654 [1:03:48<46:08,  8.14s/it]  2024-12-24 09:41:40.942 | INFO     | __main__:train_with_distillation:358 - Batch 315/654 - loss: 0.0027
Training:  49%|████▉     | 319/654 [1:04:50<43:58,  7.88s/it]  2024-12-24 09:42:42.143 | INFO     | __main__:train_with_distillation:358 - Batch 320/654 - loss: 0.0029
Training:  50%|████▉     | 324/654 [1:05:52<43:31,  7.91s/it]  2024-12-24 09:43:44.899 | INFO     | __main__:train_with_distillation:358 - Batch 325/654 - loss: 0.0028
Training:  50%|█████     | 329/654 [1:06:54<42:30,  7.85s/it]  2024-12-24 09:44:46.728 | INFO     | __main__:train_with_distillation:358 - Batch 330/654 - loss: 0.0025
Training:  51%|█████     | 334/654 [1:08:00<43:17,  8.12s/it]  2024-12-24 09:45:52.079 | INFO     | __main__:train_with_distillation:358 - Batch 335/654 - loss: 0.0027
Training:  52%|█████▏    | 339/654 [1:09:05<43:06,  8.21s/it]  2024-12-24 09:46:57.449 | INFO     | __main__:train_with_distillation:358 - Batch 340/654 - loss: 0.0022
Training:  53%|█████▎    | 344/654 [1:10:13<43:47,  8.48s/it]  2024-12-24 09:48:05.627 | INFO     | __main__:train_with_distillation:358 - Batch 345/654 - loss: 0.0021
Training:  53%|█████▎    | 349/654 [1:11:20<42:52,  8.44s/it]  2024-12-24 09:49:12.213 | INFO     | __main__:train_with_distillation:358 - Batch 350/654 - loss: 0.0019
Training:  54%|█████▍    | 354/654 [1:12:24<41:06,  8.22s/it]  2024-12-24 09:50:16.377 | INFO     | __main__:train_with_distillation:358 - Batch 355/654 - loss: 0.0025
Training:  55%|█████▍    | 359/654 [1:13:30<40:37,  8.26s/it]  2024-12-24 09:51:21.949 | INFO     | __main__:train_with_distillation:358 - Batch 360/654 - loss: 0.0017
Training:  56%|█████▌    | 364/654 [1:14:35<39:51,  8.25s/it]  2024-12-24 09:52:27.130 | INFO     | __main__:train_with_distillation:358 - Batch 365/654 - loss: 0.0016
Training:  56%|█████▋    | 369/654 [1:15:40<39:08,  8.24s/it]2024-12-24 09:53:32.301 | INFO     | __main__:train_with_distillation:358 - Batch 370/654 - loss: 0.0019
Training:  57%|█████▋    | 374/654 [1:16:45<38:21,  8.22s/it]2024-12-24 09:54:37.256 | INFO     | __main__:train_with_distillation:358 - Batch 375/654 - loss: 0.0037
Training:  58%|█████▊    | 379/654 [1:17:49<37:29,  8.18s/it]2024-12-24 09:55:41.838 | INFO     | __main__:train_with_distillation:358 - Batch 380/654 - loss: 0.0095
Training:  59%|█████▊    | 384/654 [1:18:55<37:07,  8.25s/it]2024-12-24 09:56:47.437 | INFO     | __main__:train_with_distillation:358 - Batch 385/654 - loss: 0.0046
Training:  59%|█████▉    | 389/654 [1:20:02<37:03,  8.39s/it]2024-12-24 09:57:54.404 | INFO     | __main__:train_with_distillation:358 - Batch 390/654 - loss: 0.0028
Training:  60%|██████    | 394/654 [1:21:06<35:37,  8.22s/it]2024-12-24 09:58:58.792 | INFO     | __main__:train_with_distillation:358 - Batch 395/654 - loss: 0.0033
Training:  61%|██████    | 399/654 [1:22:13<35:24,  8.33s/it]2024-12-24 10:00:05.163 | INFO     | __main__:train_with_distillation:358 - Batch 400/654 - loss: 0.0037
Training:  62%|██████▏   | 404/654 [1:23:17<34:10,  8.20s/it]2024-12-24 10:01:09.532 | INFO     | __main__:train_with_distillation:358 - Batch 405/654 - loss: 0.0031
Training:  63%|██████▎   | 409/654 [1:24:21<33:18,  8.16s/it]2024-12-24 10:02:13.918 | INFO     | __main__:train_with_distillation:358 - Batch 410/654 - loss: 0.0032
Training:  63%|██████▎   | 414/654 [1:25:27<32:50,  8.21s/it]2024-12-24 10:03:19.105 | INFO     | __main__:train_with_distillation:358 - Batch 415/654 - loss: 0.0024
Training:  64%|██████▍   | 419/654 [1:26:35<33:11,  8.48s/it]2024-12-24 10:04:27.281 | INFO     | __main__:train_with_distillation:358 - Batch 420/654 - loss: 0.0027
Training:  65%|██████▍   | 424/654 [1:27:41<32:15,  8.42s/it]2024-12-24 10:05:33.646 | INFO     | __main__:train_with_distillation:358 - Batch 425/654 - loss: 0.0024
Training:  66%|██████▌   | 429/654 [1:28:46<31:07,  8.30s/it]2024-12-24 10:06:38.873 | INFO     | __main__:train_with_distillation:358 - Batch 430/654 - loss: 0.0028
Training:  66%|██████▋   | 434/654 [1:29:48<29:17,  7.99s/it]2024-12-24 10:07:40.813 | INFO     | __main__:train_with_distillation:358 - Batch 435/654 - loss: 0.0024
Training:  67%|██████▋   | 439/654 [1:30:51<28:26,  7.94s/it]2024-12-24 10:08:43.407 | INFO     | __main__:train_with_distillation:358 - Batch 440/654 - loss: 0.0028
Training:  68%|██████▊   | 444/654 [1:31:54<27:56,  7.98s/it]2024-12-24 10:09:46.779 | INFO     | __main__:train_with_distillation:358 - Batch 445/654 - loss: 0.0030
Training:  69%|██████▊   | 449/654 [1:32:59<27:37,  8.08s/it]2024-12-24 10:10:51.157 | INFO     | __main__:train_with_distillation:358 - Batch 450/654 - loss: 0.0029
Training:  69%|██████▉   | 454/654 [1:34:04<27:26,  8.23s/it]2024-12-24 10:11:56.946 | INFO     | __main__:train_with_distillation:358 - Batch 455/654 - loss: 0.0029
Training:  70%|███████   | 459/654 [1:35:08<26:16,  8.09s/it]2024-12-24 10:13:00.314 | INFO     | __main__:train_with_distillation:358 - Batch 460/654 - loss: 0.0028
Training:  71%|███████   | 464/654 [1:36:13<25:55,  8.18s/it]2024-12-24 10:14:05.496 | INFO     | __main__:train_with_distillation:358 - Batch 465/654 - loss: 0.0040
Training:  72%|███████▏  | 469/654 [1:37:19<25:29,  8.27s/it]2024-12-24 10:15:11.251 | INFO     | __main__:train_with_distillation:358 - Batch 470/654 - loss: 0.0043
Training:  72%|███████▏  | 474/654 [1:38:22<24:14,  8.08s/it]2024-12-24 10:16:14.439 | INFO     | __main__:train_with_distillation:358 - Batch 475/654 - loss: 0.0027
Training:  73%|███████▎  | 479/654 [1:39:26<23:40,  8.12s/it]2024-12-24 10:17:18.828 | INFO     | __main__:train_with_distillation:358 - Batch 480/654 - loss: 0.0024
Training:  74%|███████▍  | 484/654 [1:40:33<23:38,  8.34s/it]2024-12-24 10:18:25.809 | INFO     | __main__:train_with_distillation:358 - Batch 485/654 - loss: 0.0016
Training:  75%|███████▍  | 489/654 [1:41:39<22:53,  8.32s/it]2024-12-24 10:19:31.561 | INFO     | __main__:train_with_distillation:358 - Batch 490/654 - loss: 0.0020
Training:  76%|███████▌  | 494/654 [1:42:44<21:54,  8.22s/it]2024-12-24 10:20:36.164 | INFO     | __main__:train_with_distillation:358 - Batch 495/654 - loss: 0.0022
Training:  76%|███████▋  | 499/654 [1:43:49<21:18,  8.25s/it]2024-12-24 10:21:41.554 | INFO     | __main__:train_with_distillation:358 - Batch 500/654 - loss: 0.0019
Training:  77%|███████▋  | 504/654 [1:44:53<20:19,  8.13s/it]2024-12-24 10:22:45.381 | INFO     | __main__:train_with_distillation:358 - Batch 505/654 - loss: 0.0016
Training:  78%|███████▊  | 509/654 [1:46:01<20:24,  8.44s/it]2024-12-24 10:23:53.489 | INFO     | __main__:train_with_distillation:358 - Batch 510/654 - loss: 0.0016
Training:  79%|███████▊  | 514/654 [1:47:08<19:39,  8.42s/it]2024-12-24 10:25:00.086 | INFO     | __main__:train_with_distillation:358 - Batch 515/654 - loss: 0.0019
Training:  79%|███████▉  | 519/654 [1:48:14<18:51,  8.38s/it]2024-12-24 10:26:06.247 | INFO     | __main__:train_with_distillation:358 - Batch 520/654 - loss: 0.0054
Training:  80%|████████  | 524/654 [1:49:19<17:53,  8.26s/it]2024-12-24 10:27:11.068 | INFO     | __main__:train_with_distillation:358 - Batch 525/654 - loss: 0.0026
Training:  81%|████████  | 529/654 [1:50:25<17:18,  8.31s/it]2024-12-24 10:28:17.040 | INFO     | __main__:train_with_distillation:358 - Batch 530/654 - loss: 0.0035
Training:  82%|████████▏ | 534/654 [1:51:31<16:46,  8.39s/it]2024-12-24 10:29:23.749 | INFO     | __main__:train_with_distillation:358 - Batch 535/654 - loss: 0.0026
Training:  82%|████████▏ | 539/654 [1:52:39<16:14,  8.47s/it]2024-12-24 10:30:31.144 | INFO     | __main__:train_with_distillation:358 - Batch 540/654 - loss: 0.0029
Training:  83%|████████▎ | 544/654 [1:53:45<15:27,  8.43s/it]2024-12-24 10:31:37.710 | INFO     | __main__:train_with_distillation:358 - Batch 545/654 - loss: 0.0022
Training:  84%|████████▍ | 549/654 [1:54:51<14:36,  8.35s/it]2024-12-24 10:32:43.476 | INFO     | __main__:train_with_distillation:358 - Batch 550/654 - loss: 0.0028
Training:  85%|████████▍ | 554/654 [1:55:57<13:50,  8.31s/it]2024-12-24 10:33:49.067 | INFO     | __main__:train_with_distillation:358 - Batch 555/654 - loss: 0.0022
Training:  85%|████████▌ | 559/654 [1:57:03<13:13,  8.35s/it]2024-12-24 10:34:55.365 | INFO     | __main__:train_with_distillation:358 - Batch 560/654 - loss: 0.0019
Training:  86%|████████▌ | 564/654 [1:58:14<13:12,  8.80s/it]2024-12-24 10:36:06.933 | INFO     | __main__:train_with_distillation:358 - Batch 565/654 - loss: 0.0022
Training:  87%|████████▋ | 569/654 [1:59:19<11:52,  8.38s/it]2024-12-24 10:37:11.507 | INFO     | __main__:train_with_distillation:358 - Batch 570/654 - loss: 0.0020
Training:  88%|████████▊ | 574/654 [2:00:25<11:09,  8.37s/it]2024-12-24 10:38:17.690 | INFO     | __main__:train_with_distillation:358 - Batch 575/654 - loss: 0.0017
Training:  89%|████████▊ | 579/654 [2:01:31<10:26,  8.35s/it]2024-12-24 10:39:23.665 | INFO     | __main__:train_with_distillation:358 - Batch 580/654 - loss: 0.0020
Training:  89%|████████▉ | 584/654 [2:02:37<09:41,  8.31s/it]2024-12-24 10:40:29.285 | INFO     | __main__:train_with_distillation:358 - Batch 585/654 - loss: 0.0021
Training:  90%|█████████ | 589/654 [2:03:41<08:53,  8.21s/it]2024-12-24 10:41:33.846 | INFO     | __main__:train_with_distillation:358 - Batch 590/654 - loss: 0.0022
Training:  91%|█████████ | 594/654 [2:04:47<08:17,  8.29s/it]2024-12-24 10:42:39.786 | INFO     | __main__:train_with_distillation:358 - Batch 595/654 - loss: 0.0015
Training:  92%|█████████▏| 599/654 [2:05:53<07:36,  8.31s/it]2024-12-24 10:43:45.579 | INFO     | __main__:train_with_distillation:358 - Batch 600/654 - loss: 0.0019
Training:  92%|█████████▏| 604/654 [2:06:57<06:47,  8.15s/it]2024-12-24 10:44:49.418 | INFO     | __main__:train_with_distillation:358 - Batch 605/654 - loss: 0.0021
Training:  93%|█████████▎| 609/654 [2:08:01<06:04,  8.09s/it]2024-12-24 10:45:53.214 | INFO     | __main__:train_with_distillation:358 - Batch 610/654 - loss: 0.0017
Training:  94%|█████████▍| 614/654 [2:09:07<05:30,  8.27s/it]2024-12-24 10:46:59.395 | INFO     | __main__:train_with_distillation:358 - Batch 615/654 - loss: 0.0015
Training:  95%|█████████▍| 619/654 [2:10:12<04:47,  8.20s/it]2024-12-24 10:48:04.001 | INFO     | __main__:train_with_distillation:358 - Batch 620/654 - loss: 0.0021
Training:  95%|█████████▌| 624/654 [2:11:17<04:07,  8.26s/it]2024-12-24 10:49:09.570 | INFO     | __main__:train_with_distillation:358 - Batch 625/654 - loss: 0.0013
Training:  96%|█████████▌| 629/654 [2:12:21<03:23,  8.13s/it]2024-12-24 10:50:13.323 | INFO     | __main__:train_with_distillation:358 - Batch 630/654 - loss: 0.0015
Training:  97%|█████████▋| 634/654 [2:13:26<02:44,  8.23s/it]2024-12-24 10:51:18.881 | INFO     | __main__:train_with_distillation:358 - Batch 635/654 - loss: 0.0015
Training:  98%|█████████▊| 639/654 [2:14:32<02:03,  8.23s/it]2024-12-24 10:52:24.072 | INFO     | __main__:train_with_distillation:358 - Batch 640/654 - loss: 0.0015
Training:  98%|█████████▊| 644/654 [2:15:36<01:21,  8.15s/it]2024-12-24 10:53:28.251 | INFO     | __main__:train_with_distillation:358 - Batch 645/654 - loss: 0.0013
Training:  99%|█████████▉| 649/654 [2:16:40<00:40,  8.11s/it]2024-12-24 10:54:32.226 | INFO     | __main__:train_with_distillation:358 - Batch 650/654 - loss: 0.0016
Training: 100%|█████████▉| 652/654 [2:17:45<00:24, 12.41s/it]2024-12-24 10:55:37.963 | INFO     | __main__:train_with_distillation:358 - Batch 654/654 - loss: 0.0017
Training: 100%|██████████| 654/654 [2:18:50<00:00, 12.74s/it]

Process finished with exit code 0
