F:\Anaconda\envs\pytorch\python.exe F:/NLP大作业/SimCSE-Pytorch-master/ESimCSE/tongyi_distill_train.py
2024-12-24 13:16:09.855 | INFO     | __main__:<module>:499 - Starting training process with knowledge distillation from Tongyi embeddings.
2024-12-24 13:16:09.855 | INFO     | __main__:<module>:500 - Namespace(batch_size=16, data_path='../data/STS-B/', device='cuda:0', dropout=0.15, dup_rate=0.15, lr=3e-05, max_length=50, pooler='first-last-avg', pretrain_model_path='F:\\models\\bert-base-chinese', q_size=64, save_path='./model_save', teacher_save_path='./cnsd_sts_train_unsup_embeddings_768.json')
Using cuda:0 device.

2024-12-24 13:16:10.154 | INFO     | __main__:<module>:505 - Test Embeddings长度: 1024
2024-12-24 13:16:10.181 | INFO     | __main__:main:424 - Generating/updating embeddings...
2024-12-24 13:16:12.420 | INFO     | __main__:generate_teacher_embeddings:166 - Total sentences: 10462, Remaining to embed: 0
Generating embeddings: 0it [00:00, ?it/s]
2024-12-24 13:16:12.421 | INFO     | __main__:generate_teacher_embeddings:193 - Embedding generation completed. Saved to ./cnsd_sts_train_unsup_embeddings_768.json
2024-12-24 13:16:15.648 | INFO     | __main__:train_with_distillation:322 - Applying PCA to teacher embeddings...
2024-12-24 13:16:15.648 | INFO     | __main__:apply_pca:43 - PCA skipped because n_components (768) matches the input dimension (768).
Training:   0%|          | 0/654 [00:00<?, ?it/s]original_dim: 768
PCA: n_components: 768
F:\Anaconda\envs\pytorch\lib\site-packages\transformers\models\bert\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\cb\pytorch_1000000000000\work\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:455.)
  attn_output = torch.nn.functional.scaled_dot_product_attention(
Training:   0%|          | 3/654 [01:01<2:53:22, 15.98s/it] 2024-12-24 13:17:17.395 | INFO     | __main__:train_with_distillation:358 - Batch 5/654 - loss: 0.0645
Training:   0%|          | 3/654 [01:16<2:53:22, 15.98s/it]2024-12-24 13:18:37.338 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.5725 at batch 5, model saved.
Training:   1%|▏         | 9/654 [02:21<1:49:57, 10.23s/it]2024-12-24 13:18:37.702 | INFO     | __main__:train_with_distillation:358 - Batch 10/654 - loss: 0.0411
Training:   1%|▏         | 9/654 [02:36<1:49:57, 10.23s/it]2024-12-24 13:19:37.578 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.5866 at batch 10, model saved.
Training:   2%|▏         | 14/654 [03:22<1:30:06,  8.45s/it]2024-12-24 13:19:37.944 | INFO     | __main__:train_with_distillation:358 - Batch 15/654 - loss: 0.0346
Training:   2%|▏         | 14/654 [03:36<1:30:06,  8.45s/it]2024-12-24 13:20:39.995 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.5925 at batch 15, model saved.
Training:   3%|▎         | 19/654 [04:24<1:25:27,  8.08s/it]2024-12-24 13:20:40.360 | INFO     | __main__:train_with_distillation:358 - Batch 20/654 - loss: 0.0325
Training:   3%|▎         | 19/654 [04:36<1:25:27,  8.08s/it]2024-12-24 13:21:38.971 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.6017 at batch 20, model saved.
Training:   4%|▎         | 24/654 [05:23<1:20:29,  7.67s/it]2024-12-24 13:21:39.336 | INFO     | __main__:train_with_distillation:358 - Batch 25/654 - loss: 0.0281
Training:   4%|▎         | 24/654 [05:37<1:20:29,  7.67s/it]2024-12-24 13:22:39.767 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.6191 at batch 25, model saved.
Training:   4%|▍         | 29/654 [06:24<1:19:58,  7.68s/it]2024-12-24 13:22:40.129 | INFO     | __main__:train_with_distillation:358 - Batch 30/654 - loss: 0.0284
Training:   4%|▍         | 29/654 [06:37<1:19:58,  7.68s/it]2024-12-24 13:23:40.952 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.6245 at batch 30, model saved.
Training:   5%|▌         | 34/654 [07:25<1:19:42,  7.71s/it]2024-12-24 13:23:41.313 | INFO     | __main__:train_with_distillation:358 - Batch 35/654 - loss: 0.0279
Training:   6%|▌         | 39/654 [08:28<1:20:32,  7.86s/it]2024-12-24 13:24:44.069 | INFO     | __main__:train_with_distillation:358 - Batch 40/654 - loss: 0.0219
Training:   7%|▋         | 44/654 [09:32<1:21:19,  8.00s/it]2024-12-24 13:25:47.987 | INFO     | __main__:train_with_distillation:358 - Batch 45/654 - loss: 0.0228
Training:   7%|▋         | 49/654 [10:27<1:13:52,  7.33s/it]2024-12-24 13:26:43.163 | INFO     | __main__:train_with_distillation:358 - Batch 50/654 - loss: 0.0201
Training:   8%|▊         | 54/654 [11:20<1:09:07,  6.91s/it]2024-12-24 13:27:36.109 | INFO     | __main__:train_with_distillation:358 - Batch 55/654 - loss: 0.0179
Training:   9%|▉         | 59/654 [12:06<1:01:40,  6.22s/it]2024-12-24 13:28:22.424 | INFO     | __main__:train_with_distillation:358 - Batch 60/654 - loss: 0.0171
Training:  10%|▉         | 64/654 [12:54<1:00:12,  6.12s/it]2024-12-24 13:29:10.432 | INFO     | __main__:train_with_distillation:358 - Batch 65/654 - loss: 0.0145
Training:  11%|█         | 69/654 [13:53<1:07:49,  6.96s/it]2024-12-24 13:30:08.891 | INFO     | __main__:train_with_distillation:358 - Batch 70/654 - loss: 0.0132
Training:  11%|█▏        | 74/654 [14:54<1:12:19,  7.48s/it]2024-12-24 13:31:10.278 | INFO     | __main__:train_with_distillation:358 - Batch 75/654 - loss: 0.0142
Training:  12%|█▏        | 79/654 [15:57<1:14:32,  7.78s/it]2024-12-24 13:32:13.056 | INFO     | __main__:train_with_distillation:358 - Batch 80/654 - loss: 0.0114
Training:  13%|█▎        | 84/654 [16:53<1:09:40,  7.33s/it]2024-12-24 13:33:09.236 | INFO     | __main__:train_with_distillation:358 - Batch 85/654 - loss: 0.0103
Training:  14%|█▎        | 89/654 [17:46<1:05:24,  6.95s/it]2024-12-24 13:34:02.568 | INFO     | __main__:train_with_distillation:358 - Batch 90/654 - loss: 0.0099
Training:  14%|█▍        | 94/654 [18:33<58:19,  6.25s/it]  2024-12-24 13:34:49.095 | INFO     | __main__:train_with_distillation:358 - Batch 95/654 - loss: 0.0095
Training:  15%|█▌        | 99/654 [19:26<1:00:26,  6.53s/it]2024-12-24 13:35:41.954 | INFO     | __main__:train_with_distillation:358 - Batch 100/654 - loss: 0.0080
Training:  16%|█▌        | 104/654 [20:23<1:04:06,  6.99s/it]2024-12-24 13:36:39.166 | INFO     | __main__:train_with_distillation:358 - Batch 105/654 - loss: 0.0073
Training:  17%|█▋        | 109/654 [21:21<1:05:31,  7.21s/it]2024-12-24 13:37:37.139 | INFO     | __main__:train_with_distillation:358 - Batch 110/654 - loss: 0.0070
Training:  17%|█▋        | 114/654 [22:19<1:05:37,  7.29s/it]2024-12-24 13:38:35.120 | INFO     | __main__:train_with_distillation:358 - Batch 115/654 - loss: 0.0071
Training:  18%|█▊        | 119/654 [23:15<1:04:11,  7.20s/it]2024-12-24 13:39:31.682 | INFO     | __main__:train_with_distillation:358 - Batch 120/654 - loss: 0.0071
Training:  19%|█▉        | 124/654 [24:18<1:08:00,  7.70s/it]2024-12-24 13:40:34.694 | INFO     | __main__:train_with_distillation:358 - Batch 125/654 - loss: 0.0058
Training:  20%|█▉        | 129/654 [25:19<1:07:00,  7.66s/it]2024-12-24 13:41:35.092 | INFO     | __main__:train_with_distillation:358 - Batch 130/654 - loss: 0.0053
Training:  20%|██        | 134/654 [26:10<59:35,  6.88s/it]  2024-12-24 13:42:26.229 | INFO     | __main__:train_with_distillation:358 - Batch 135/654 - loss: 0.0046
Training:  21%|██▏       | 139/654 [26:58<54:25,  6.34s/it]  2024-12-24 13:43:14.159 | INFO     | __main__:train_with_distillation:358 - Batch 140/654 - loss: 0.0050
Training:  22%|██▏       | 144/654 [28:02<1:03:23,  7.46s/it]2024-12-24 13:44:17.787 | INFO     | __main__:train_with_distillation:358 - Batch 145/654 - loss: 0.0052
Training:  23%|██▎       | 149/654 [29:01<1:02:53,  7.47s/it]2024-12-24 13:45:16.971 | INFO     | __main__:train_with_distillation:358 - Batch 150/654 - loss: 0.0048
Training:  24%|██▎       | 154/654 [29:52<56:54,  6.83s/it]  2024-12-24 13:46:08.315 | INFO     | __main__:train_with_distillation:358 - Batch 155/654 - loss: 0.0048
Training:  24%|██▍       | 159/654 [30:39<51:47,  6.28s/it]  2024-12-24 13:46:55.673 | INFO     | __main__:train_with_distillation:358 - Batch 160/654 - loss: 0.0047
Training:  25%|██▌       | 164/654 [31:39<57:54,  7.09s/it]  2024-12-24 13:47:55.127 | INFO     | __main__:train_with_distillation:358 - Batch 165/654 - loss: 0.0057
Training:  26%|██▌       | 169/654 [32:30<54:07,  6.70s/it]  2024-12-24 13:48:46.461 | INFO     | __main__:train_with_distillation:358 - Batch 170/654 - loss: 0.0045
Training:  27%|██▋       | 174/654 [33:17<49:19,  6.16s/it]  2024-12-24 13:49:32.982 | INFO     | __main__:train_with_distillation:358 - Batch 175/654 - loss: 0.0470
Training:  27%|██▋       | 179/654 [34:05<48:28,  6.12s/it]  2024-12-24 13:50:21.206 | INFO     | __main__:train_with_distillation:358 - Batch 180/654 - loss: 0.0051
Training:  28%|██▊       | 184/654 [35:01<52:54,  6.75s/it]  2024-12-24 13:51:17.244 | INFO     | __main__:train_with_distillation:358 - Batch 185/654 - loss: 0.0043
Training:  29%|██▉       | 189/654 [36:05<58:59,  7.61s/it]  2024-12-24 13:52:21.026 | INFO     | __main__:train_with_distillation:358 - Batch 190/654 - loss: 0.0040
Training:  30%|██▉       | 194/654 [37:02<56:11,  7.33s/it]  2024-12-24 13:53:17.818 | INFO     | __main__:train_with_distillation:358 - Batch 195/654 - loss: 0.0045
Training:  30%|███       | 199/654 [37:50<49:22,  6.51s/it]  2024-12-24 13:54:05.930 | INFO     | __main__:train_with_distillation:358 - Batch 200/654 - loss: 0.0080
Training:  31%|███       | 204/654 [38:42<49:23,  6.58s/it]  2024-12-24 13:54:58.323 | INFO     | __main__:train_with_distillation:358 - Batch 205/654 - loss: 0.0040
Training:  32%|███▏      | 209/654 [39:38<51:00,  6.88s/it]  2024-12-24 13:55:53.935 | INFO     | __main__:train_with_distillation:358 - Batch 210/654 - loss: 0.0040
Training:  33%|███▎      | 214/654 [40:37<53:42,  7.32s/it]  2024-12-24 13:56:53.734 | INFO     | __main__:train_with_distillation:358 - Batch 215/654 - loss: 0.0034
Training:  33%|███▎      | 219/654 [41:40<55:38,  7.67s/it]  2024-12-24 13:57:55.913 | INFO     | __main__:train_with_distillation:358 - Batch 220/654 - loss: 0.0036
Training:  34%|███▍      | 224/654 [42:41<55:17,  7.72s/it]  2024-12-24 13:58:57.133 | INFO     | __main__:train_with_distillation:358 - Batch 225/654 - loss: 0.0033
Training:  35%|███▌      | 229/654 [43:40<53:31,  7.56s/it]  2024-12-24 13:59:56.271 | INFO     | __main__:train_with_distillation:358 - Batch 230/654 - loss: 0.0030
Training:  36%|███▌      | 234/654 [44:37<51:09,  7.31s/it]  2024-12-24 14:00:53.047 | INFO     | __main__:train_with_distillation:358 - Batch 235/654 - loss: 0.0036
Training:  37%|███▋      | 239/654 [45:33<49:30,  7.16s/it]  2024-12-24 14:01:49.053 | INFO     | __main__:train_with_distillation:358 - Batch 240/654 - loss: 0.0029
Training:  37%|███▋      | 244/654 [46:30<48:59,  7.17s/it]  2024-12-24 14:02:45.831 | INFO     | __main__:train_with_distillation:358 - Batch 245/654 - loss: 0.0041
Training:  38%|███▊      | 249/654 [47:28<49:18,  7.30s/it]  2024-12-24 14:03:44.184 | INFO     | __main__:train_with_distillation:358 - Batch 250/654 - loss: 0.0027
Training:  39%|███▉      | 254/654 [48:25<48:18,  7.25s/it]  2024-12-24 14:04:41.240 | INFO     | __main__:train_with_distillation:358 - Batch 255/654 - loss: 0.0032
Training:  40%|███▉      | 259/654 [49:30<51:50,  7.87s/it]  2024-12-24 14:05:46.150 | INFO     | __main__:train_with_distillation:358 - Batch 260/654 - loss: 0.0035
Training:  40%|████      | 264/654 [50:34<52:04,  8.01s/it]  2024-12-24 14:06:50.132 | INFO     | __main__:train_with_distillation:358 - Batch 265/654 - loss: 0.0028
Training:  41%|████      | 269/654 [51:31<47:59,  7.48s/it]  2024-12-24 14:07:47.097 | INFO     | __main__:train_with_distillation:358 - Batch 270/654 - loss: 0.0024
Training:  42%|████▏     | 274/654 [52:29<47:03,  7.43s/it]  2024-12-24 14:08:45.677 | INFO     | __main__:train_with_distillation:358 - Batch 275/654 - loss: 0.0024
Training:  43%|████▎     | 279/654 [53:28<46:14,  7.40s/it]  2024-12-24 14:09:44.067 | INFO     | __main__:train_with_distillation:358 - Batch 280/654 - loss: 0.0020
Training:  43%|████▎     | 284/654 [54:25<44:44,  7.25s/it]  2024-12-24 14:10:40.868 | INFO     | __main__:train_with_distillation:358 - Batch 285/654 - loss: 0.0021
Training:  44%|████▍     | 289/654 [55:24<44:56,  7.39s/it]  2024-12-24 14:11:39.843 | INFO     | __main__:train_with_distillation:358 - Batch 290/654 - loss: 0.0022
Training:  45%|████▍     | 294/654 [56:23<44:40,  7.45s/it]  2024-12-24 14:12:39.022 | INFO     | __main__:train_with_distillation:358 - Batch 295/654 - loss: 0.0022
Training:  46%|████▌     | 299/654 [57:20<43:06,  7.29s/it]  2024-12-24 14:13:35.997 | INFO     | __main__:train_with_distillation:358 - Batch 300/654 - loss: 0.0017
Training:  46%|████▋     | 304/654 [58:18<42:45,  7.33s/it]  2024-12-24 14:14:34.164 | INFO     | __main__:train_with_distillation:358 - Batch 305/654 - loss: 0.0020
Training:  47%|████▋     | 309/654 [59:23<45:22,  7.89s/it]  2024-12-24 14:15:38.946 | INFO     | __main__:train_with_distillation:358 - Batch 310/654 - loss: 0.0017
Training:  48%|████▊     | 314/654 [1:00:22<43:10,  7.62s/it]  2024-12-24 14:16:38.106 | INFO     | __main__:train_with_distillation:358 - Batch 315/654 - loss: 0.0018
Training:  49%|████▉     | 319/654 [1:01:17<40:23,  7.23s/it]  2024-12-24 14:17:33.733 | INFO     | __main__:train_with_distillation:358 - Batch 320/654 - loss: 0.0020
Training:  50%|████▉     | 324/654 [1:02:21<42:34,  7.74s/it]  2024-12-24 14:18:37.083 | INFO     | __main__:train_with_distillation:358 - Batch 325/654 - loss: 0.0016
Training:  50%|█████     | 329/654 [1:03:18<40:12,  7.42s/it]  2024-12-24 14:19:34.479 | INFO     | __main__:train_with_distillation:358 - Batch 330/654 - loss: 0.0018
Training:  51%|█████     | 334/654 [1:04:26<43:24,  8.14s/it]  2024-12-24 14:20:41.865 | INFO     | __main__:train_with_distillation:358 - Batch 335/654 - loss: 0.0025
Training:  52%|█████▏    | 339/654 [1:05:24<40:01,  7.63s/it]  2024-12-24 14:21:40.055 | INFO     | __main__:train_with_distillation:358 - Batch 340/654 - loss: 0.0026
Training:  53%|█████▎    | 344/654 [1:06:19<37:16,  7.21s/it]2024-12-24 14:22:35.429 | INFO     | __main__:train_with_distillation:358 - Batch 345/654 - loss: 0.0026
Training:  53%|█████▎    | 349/654 [1:07:10<33:55,  6.67s/it]2024-12-24 14:23:25.926 | INFO     | __main__:train_with_distillation:358 - Batch 350/654 - loss: 0.0023
Training:  54%|█████▍    | 354/654 [1:07:56<30:42,  6.14s/it]2024-12-24 14:24:12.284 | INFO     | __main__:train_with_distillation:358 - Batch 355/654 - loss: 0.0026
Training:  55%|█████▍    | 359/654 [1:08:47<31:06,  6.33s/it]2024-12-24 14:25:03.081 | INFO     | __main__:train_with_distillation:358 - Batch 360/654 - loss: 0.0024
Training:  56%|█████▌    | 364/654 [1:09:38<31:08,  6.44s/it]2024-12-24 14:25:54.500 | INFO     | __main__:train_with_distillation:358 - Batch 365/654 - loss: 0.0020
Training:  56%|█████▋    | 369/654 [1:10:30<31:00,  6.53s/it]2024-12-24 14:26:46.470 | INFO     | __main__:train_with_distillation:358 - Batch 370/654 - loss: 0.0019
Training:  57%|█████▋    | 374/654 [1:11:25<31:46,  6.81s/it]2024-12-24 14:27:41.486 | INFO     | __main__:train_with_distillation:358 - Batch 375/654 - loss: 0.0021
Training:  58%|█████▊    | 379/654 [1:12:18<30:56,  6.75s/it]2024-12-24 14:28:34.643 | INFO     | __main__:train_with_distillation:358 - Batch 380/654 - loss: 0.0014
Training:  59%|█████▊    | 384/654 [1:13:24<34:48,  7.73s/it]2024-12-24 14:29:39.890 | INFO     | __main__:train_with_distillation:358 - Batch 385/654 - loss: 0.0018
Training:  59%|█████▉    | 389/654 [1:14:28<35:09,  7.96s/it]2024-12-24 14:30:43.846 | INFO     | __main__:train_with_distillation:358 - Batch 390/654 - loss: 0.0014
Training:  60%|██████    | 394/654 [1:15:30<34:16,  7.91s/it]2024-12-24 14:31:46.204 | INFO     | __main__:train_with_distillation:358 - Batch 395/654 - loss: 0.0014
Training:  61%|██████    | 399/654 [1:16:20<29:05,  6.85s/it]2024-12-24 14:32:35.949 | INFO     | __main__:train_with_distillation:358 - Batch 400/654 - loss: 0.0016
Training:  62%|██████▏   | 404/654 [1:17:12<27:50,  6.68s/it]2024-12-24 14:33:28.150 | INFO     | __main__:train_with_distillation:358 - Batch 405/654 - loss: 0.0014
Training:  63%|██████▎   | 409/654 [1:18:17<31:31,  7.72s/it]2024-12-24 14:34:33.541 | INFO     | __main__:train_with_distillation:358 - Batch 410/654 - loss: 0.0012
Training:  63%|██████▎   | 414/654 [1:19:19<31:09,  7.79s/it]2024-12-24 14:35:35.475 | INFO     | __main__:train_with_distillation:358 - Batch 415/654 - loss: 0.0016
Training:  64%|██████▍   | 419/654 [1:20:21<30:30,  7.79s/it]2024-12-24 14:36:37.108 | INFO     | __main__:train_with_distillation:358 - Batch 420/654 - loss: 0.0015
Training:  65%|██████▍   | 424/654 [1:21:22<29:39,  7.74s/it]2024-12-24 14:37:38.133 | INFO     | __main__:train_with_distillation:358 - Batch 425/654 - loss: 0.0014
Training:  66%|██████▌   | 429/654 [1:22:21<28:26,  7.58s/it]2024-12-24 14:38:37.478 | INFO     | __main__:train_with_distillation:358 - Batch 430/654 - loss: 0.0014
Training:  66%|██████▋   | 434/654 [1:23:21<27:47,  7.58s/it]2024-12-24 14:39:37.467 | INFO     | __main__:train_with_distillation:358 - Batch 435/654 - loss: 0.0014
Training:  67%|██████▋   | 439/654 [1:24:19<26:27,  7.38s/it]2024-12-24 14:40:35.040 | INFO     | __main__:train_with_distillation:358 - Batch 440/654 - loss: 0.0014
Training:  68%|██████▊   | 444/654 [1:25:21<26:48,  7.66s/it]2024-12-24 14:41:36.786 | INFO     | __main__:train_with_distillation:358 - Batch 445/654 - loss: 0.0015
Training:  69%|██████▊   | 449/654 [1:26:22<26:30,  7.76s/it]2024-12-24 14:42:38.580 | INFO     | __main__:train_with_distillation:358 - Batch 450/654 - loss: 0.0013
Training:  69%|██████▉   | 454/654 [1:27:25<26:08,  7.84s/it]2024-12-24 14:43:41.012 | INFO     | __main__:train_with_distillation:358 - Batch 455/654 - loss: 0.0016
Training:  70%|███████   | 459/654 [1:28:27<25:31,  7.85s/it]2024-12-24 14:44:43.187 | INFO     | __main__:train_with_distillation:358 - Batch 460/654 - loss: 0.0012
Training:  71%|███████   | 464/654 [1:29:27<24:25,  7.71s/it]2024-12-24 14:45:43.590 | INFO     | __main__:train_with_distillation:358 - Batch 465/654 - loss: 0.0012
Training:  72%|███████▏  | 469/654 [1:30:29<23:54,  7.76s/it]2024-12-24 14:46:45.150 | INFO     | __main__:train_with_distillation:358 - Batch 470/654 - loss: 0.0023
Training:  72%|███████▏  | 474/654 [1:31:24<21:43,  7.24s/it]2024-12-24 14:47:40.269 | INFO     | __main__:train_with_distillation:358 - Batch 475/654 - loss: 0.0020
Training:  73%|███████▎  | 479/654 [1:32:12<18:52,  6.47s/it]2024-12-24 14:48:28.241 | INFO     | __main__:train_with_distillation:358 - Batch 480/654 - loss: 0.0123
Training:  74%|███████▍  | 484/654 [1:33:17<21:41,  7.66s/it]2024-12-24 14:49:33.732 | INFO     | __main__:train_with_distillation:358 - Batch 485/654 - loss: 0.0025
Training:  75%|███████▍  | 489/654 [1:34:24<22:27,  8.16s/it]2024-12-24 14:50:40.419 | INFO     | __main__:train_with_distillation:358 - Batch 490/654 - loss: 0.0016
Training:  76%|███████▌  | 494/654 [1:35:26<21:06,  7.91s/it]2024-12-24 14:51:41.986 | INFO     | __main__:train_with_distillation:358 - Batch 495/654 - loss: 0.0017
Training:  76%|███████▋  | 499/654 [1:36:16<17:44,  6.87s/it]2024-12-24 14:52:31.966 | INFO     | __main__:train_with_distillation:358 - Batch 500/654 - loss: 0.0017
Training:  77%|███████▋  | 504/654 [1:37:06<16:14,  6.50s/it]2024-12-24 14:53:21.795 | INFO     | __main__:train_with_distillation:358 - Batch 505/654 - loss: 0.0938
Training:  78%|███████▊  | 509/654 [1:38:06<17:27,  7.22s/it]2024-12-24 14:54:21.927 | INFO     | __main__:train_with_distillation:358 - Batch 510/654 - loss: 0.0018
Training:  79%|███████▊  | 514/654 [1:39:13<18:53,  8.10s/it]2024-12-24 14:55:29.592 | INFO     | __main__:train_with_distillation:358 - Batch 515/654 - loss: 0.0013
Training:  79%|███████▊  | 514/654 [1:39:31<18:53,  8.10s/it]2024-12-24 14:56:35.296 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.6288 at batch 515, model saved.
Training:  79%|███████▉  | 519/654 [1:40:19<18:36,  8.27s/it]2024-12-24 14:56:35.700 | INFO     | __main__:train_with_distillation:358 - Batch 520/654 - loss: 0.0025
Training:  80%|████████  | 524/654 [1:41:28<18:33,  8.57s/it]2024-12-24 14:57:44.734 | INFO     | __main__:train_with_distillation:358 - Batch 525/654 - loss: 0.0022
Training:  81%|████████  | 529/654 [1:42:34<17:29,  8.39s/it]2024-12-24 14:58:50.415 | INFO     | __main__:train_with_distillation:358 - Batch 530/654 - loss: 0.0026
Training:  82%|████████▏ | 534/654 [1:43:39<16:32,  8.27s/it]2024-12-24 14:59:55.393 | INFO     | __main__:train_with_distillation:358 - Batch 535/654 - loss: 0.0016
Training:  82%|████████▏ | 539/654 [1:44:42<15:22,  8.03s/it]2024-12-24 15:00:57.853 | INFO     | __main__:train_with_distillation:358 - Batch 540/654 - loss: 0.0017
Training:  83%|████████▎ | 544/654 [1:45:44<14:33,  7.94s/it]2024-12-24 15:02:00.294 | INFO     | __main__:train_with_distillation:358 - Batch 545/654 - loss: 0.0031
Training:  84%|████████▍ | 549/654 [1:46:47<13:52,  7.93s/it]2024-12-24 15:03:02.925 | INFO     | __main__:train_with_distillation:358 - Batch 550/654 - loss: 0.0018
Training:  85%|████████▍ | 554/654 [1:47:47<12:48,  7.69s/it]2024-12-24 15:04:02.794 | INFO     | __main__:train_with_distillation:358 - Batch 555/654 - loss: 0.0016
Training:  85%|████████▌ | 559/654 [1:48:49<12:21,  7.80s/it]2024-12-24 15:05:05.002 | INFO     | __main__:train_with_distillation:358 - Batch 560/654 - loss: 0.0020
Training:  86%|████████▌ | 564/654 [1:49:52<11:52,  7.92s/it]2024-12-24 15:06:08.158 | INFO     | __main__:train_with_distillation:358 - Batch 565/654 - loss: 0.0031
Training:  87%|████████▋ | 569/654 [1:50:50<10:44,  7.58s/it]2024-12-24 15:07:06.738 | INFO     | __main__:train_with_distillation:358 - Batch 570/654 - loss: 0.0012
Training:  88%|████████▊ | 574/654 [1:51:50<10:04,  7.55s/it]2024-12-24 15:08:06.396 | INFO     | __main__:train_with_distillation:358 - Batch 575/654 - loss: 0.0014
Training:  89%|████████▊ | 579/654 [1:52:43<08:41,  6.95s/it]2024-12-24 15:08:58.871 | INFO     | __main__:train_with_distillation:358 - Batch 580/654 - loss: 0.0048
Training:  89%|████████▉ | 584/654 [1:53:45<08:50,  7.58s/it]2024-12-24 15:10:01.485 | INFO     | __main__:train_with_distillation:358 - Batch 585/654 - loss: 0.0025
Training:  90%|█████████ | 589/654 [1:54:43<07:59,  7.38s/it]2024-12-24 15:10:59.035 | INFO     | __main__:train_with_distillation:358 - Batch 590/654 - loss: 0.0020
Training:  91%|█████████ | 594/654 [1:55:47<07:49,  7.83s/it]2024-12-24 15:12:02.851 | INFO     | __main__:train_with_distillation:358 - Batch 595/654 - loss: 0.0020
Training:  92%|█████████▏| 599/654 [1:56:49<07:11,  7.85s/it]2024-12-24 15:13:05.018 | INFO     | __main__:train_with_distillation:358 - Batch 600/654 - loss: 0.0015
Training:  92%|█████████▏| 599/654 [1:57:02<07:11,  7.85s/it]2024-12-24 15:14:07.505 | INFO     | __main__:train_with_distillation:364 - New best corrcoef: 0.6348 at batch 600, model saved.
Training:  92%|█████████▏| 604/654 [1:57:52<06:35,  7.91s/it]2024-12-24 15:14:07.871 | INFO     | __main__:train_with_distillation:358 - Batch 605/654 - loss: 0.0016
Training:  93%|█████████▎| 609/654 [1:58:56<06:02,  8.05s/it]2024-12-24 15:15:12.121 | INFO     | __main__:train_with_distillation:358 - Batch 610/654 - loss: 0.0014
Training:  94%|█████████▍| 614/654 [1:59:57<05:15,  7.88s/it]2024-12-24 15:16:13.731 | INFO     | __main__:train_with_distillation:358 - Batch 615/654 - loss: 0.0016
Training:  95%|█████████▍| 619/654 [2:00:51<04:09,  7.13s/it]2024-12-24 15:17:07.066 | INFO     | __main__:train_with_distillation:358 - Batch 620/654 - loss: 0.0017
Training:  95%|█████████▌| 624/654 [2:01:50<03:41,  7.40s/it]2024-12-24 15:18:06.669 | INFO     | __main__:train_with_distillation:358 - Batch 625/654 - loss: 0.0015
Training:  96%|█████████▌| 629/654 [2:02:54<03:14,  7.78s/it]2024-12-24 15:19:09.840 | INFO     | __main__:train_with_distillation:358 - Batch 630/654 - loss: 0.0014
Training:  97%|█████████▋| 634/654 [2:03:52<02:30,  7.52s/it]2024-12-24 15:20:08.226 | INFO     | __main__:train_with_distillation:358 - Batch 635/654 - loss: 0.0013
Training:  98%|█████████▊| 639/654 [2:04:52<01:53,  7.56s/it]2024-12-24 15:21:08.224 | INFO     | __main__:train_with_distillation:358 - Batch 640/654 - loss: 0.0019
Training:  98%|█████████▊| 644/654 [2:05:47<01:11,  7.16s/it]2024-12-24 15:22:03.167 | INFO     | __main__:train_with_distillation:358 - Batch 645/654 - loss: 0.0028
Training:  99%|█████████▉| 649/654 [2:06:43<00:35,  7.15s/it]2024-12-24 15:22:59.749 | INFO     | __main__:train_with_distillation:358 - Batch 650/654 - loss: 0.0016
Training: 100%|█████████▉| 652/654 [2:07:45<00:22, 11.37s/it]2024-12-24 15:24:01.142 | INFO     | __main__:train_with_distillation:358 - Batch 654/654 - loss: 0.0015
Training: 100%|██████████| 654/654 [2:08:51<00:00, 11.82s/it]

Process finished with exit code 0
